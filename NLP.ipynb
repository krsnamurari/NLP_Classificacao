{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "h0Wvm6moSJsP",
        "D8bXVFpMSaE3",
        "u_Be12nIVmOi",
        "l9giAzRxT9IL",
        "oeFUdLw5UNmg"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krsnamurari/NLP_Classificacao/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UNIVERSIDADE FEDERAL DE PERNAMBUCO**<br>\n",
        "**CENTRO DE INFORMÁTICA**<br>\n",
        "<br>\n",
        "**CURSO DE PÓS-GRADUAÇÃO EM CIÊNCIA DE DADOS**<br>\n",
        "**DISCIPLINA: PROJETO EM CIÊNCIA DE DADOS**<br>\n",
        "**PROFESSOR: LUCIANO BARBOSA**<br>\n",
        "<br>\n",
        "**ALUNOS: MICHELE VANESSA SERCUNDES NUNES e<br>\n",
        "           KRSNA MURARI DE ALBUQUERQUE RODRIGUES**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-nE8wy94X1Ms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importação de bibliotecas**"
      ],
      "metadata": {
        "id": "h0Wvm6moSJsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna tensorflow"
      ],
      "metadata": {
        "id": "04d-YpgVhFRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af7bf12d-6f32-4ca2-861a-2d446f86598d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-3.5.0-py3-none-any.whl (413 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.4/413.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.1-py3-none-any.whl (233 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.4/233.4 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.24)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.66.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.0 alembic-1.13.1 colorlog-6.8.2 optuna-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import optuna\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "Ij7BaUHhg_QH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**1. Coleta e Pré-processamento de Dados para Análise de Tweets**"
      ],
      "metadata": {
        "id": "D8bXVFpMSaE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOelRngmrTOW",
        "outputId": "8f2b6f0e-2018-48d2-f539-3bbaef0adc91"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "pré-processamento dos dados"
      ],
      "metadata": {
        "id": "8HbYCO5KrlCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "L8M0nVjYWt2C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "726ce653-d7d4-4af5-a83e-e13d347c25de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "# Baixar recursos necessários do NLTK\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Carregar o dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/mLabel_tweets.csv')\n",
        "\n",
        "# Função para limpeza dos tweets\n",
        "def clean_tweet(tweet):\n",
        "    # Remover menções, hashtags, URLs e caracteres especiais\n",
        "    tweet = re.sub(r'(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^RT|http.+?', '', tweet)\n",
        "    # Remover números\n",
        "    tweet = re.sub(r'\\d+', '', tweet)\n",
        "    # Converter para minúsculas\n",
        "    tweet = tweet.lower()\n",
        "    return tweet\n",
        "\n",
        "# Limpeza e tokenização dos tweets\n",
        "df['tweet'] = df['tweet'].apply(clean_tweet)\n",
        "df['tweet'] = df['tweet'].apply(nltk.word_tokenize)\n",
        "\n",
        "# Remoção de stop words e lemmatização\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['tweet'] = df['tweet'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x if word not in stop_words])\n",
        "\n",
        "# Juntar os tokens de volta em strings\n",
        "df['tweet'] = df['tweet'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Removendo a coluna ID\n",
        "df = df.drop(columns = [\"ID\"])\n",
        "\n",
        "# Vetorização dos tweets usando TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df['tweet'])\n",
        "\n",
        "# Codificação de labels\n",
        "y = pd.get_dummies(df['labels']).values\n",
        "\n",
        "# Dividir o dataset em conjuntos de treino, validação e teste\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Para outros modelos, continue usando a vetorização TF-IDF\n",
        "X_tfidf = vectorizer.fit_transform(df['tweet'])\n",
        "y_tfidf = y  # Já definido anteriormente\n",
        "\n",
        "# Extraindo os rótulos únicos\n",
        "unique_labels = set(label for label_list in df['labels'].str.split() for label in label_list)\n",
        "\n",
        "# Inicializando o MultiLabelBinarizer\n",
        "mlb = MultiLabelBinarizer(classes=sorted(unique_labels))\n",
        "\n",
        "# Aplicando a transformação\n",
        "df['labels'] = df['labels'].str.split()  # Dividindo os rótulos\n",
        "labels_binarized = mlb.fit_transform(df['labels'])\n",
        "\n",
        "# Criando um DataFrame para os rótulos binarizados\n",
        "labels_df = pd.DataFrame(labels_binarized, columns=mlb.classes_)\n",
        "\n",
        "# Juntando os rótulos binarizados ao DataFrame original\n",
        "df = df.join(labels_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('df_final.csv', sep = ',', index = False)"
      ],
      "metadata": {
        "id": "7WvvyKJA1TP_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**2. Análise de Dados**"
      ],
      "metadata": {
        "id": "u_Be12nIVmOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d8f--fyrR91R",
        "outputId": "c54cd592-20dc-42e7-e218-f1d90366e40e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        conspiracy      country  ineffective  ingredients    mandatory  \\\n",
              "count  9921.000000  9921.000000  9921.000000  9921.000000  9921.000000   \n",
              "mean      0.049088     0.020260     0.168531     0.043947     0.078923   \n",
              "std       0.216062     0.140896     0.374356     0.204988     0.269633   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "              none       pharma    political    religious       rushed  \\\n",
              "count  9921.000000  9921.000000  9921.000000  9921.000000  9921.000000   \n",
              "mean      0.063401     0.128314     0.063098     0.006451     0.148775   \n",
              "std       0.243695     0.334456     0.243152     0.080062     0.355885   \n",
              "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
              "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
              "\n",
              "       side-effect  unnecessary  \n",
              "count   9921.00000  9921.000000  \n",
              "mean       0.38353     0.072775  \n",
              "std        0.48627     0.259780  \n",
              "min        0.00000     0.000000  \n",
              "25%        0.00000     0.000000  \n",
              "50%        0.00000     0.000000  \n",
              "75%        1.00000     0.000000  \n",
              "max        1.00000     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30189df0-ba1f-4ae2-9afd-0fea64c1608d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>conspiracy</th>\n",
              "      <th>country</th>\n",
              "      <th>ineffective</th>\n",
              "      <th>ingredients</th>\n",
              "      <th>mandatory</th>\n",
              "      <th>none</th>\n",
              "      <th>pharma</th>\n",
              "      <th>political</th>\n",
              "      <th>religious</th>\n",
              "      <th>rushed</th>\n",
              "      <th>side-effect</th>\n",
              "      <th>unnecessary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.000000</td>\n",
              "      <td>9921.00000</td>\n",
              "      <td>9921.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.049088</td>\n",
              "      <td>0.020260</td>\n",
              "      <td>0.168531</td>\n",
              "      <td>0.043947</td>\n",
              "      <td>0.078923</td>\n",
              "      <td>0.063401</td>\n",
              "      <td>0.128314</td>\n",
              "      <td>0.063098</td>\n",
              "      <td>0.006451</td>\n",
              "      <td>0.148775</td>\n",
              "      <td>0.38353</td>\n",
              "      <td>0.072775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.216062</td>\n",
              "      <td>0.140896</td>\n",
              "      <td>0.374356</td>\n",
              "      <td>0.204988</td>\n",
              "      <td>0.269633</td>\n",
              "      <td>0.243695</td>\n",
              "      <td>0.334456</td>\n",
              "      <td>0.243152</td>\n",
              "      <td>0.080062</td>\n",
              "      <td>0.355885</td>\n",
              "      <td>0.48627</td>\n",
              "      <td>0.259780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30189df0-ba1f-4ae2-9afd-0fea64c1608d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30189df0-ba1f-4ae2-9afd-0fea64c1608d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30189df0-ba1f-4ae2-9afd-0fea64c1608d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e0ebf8e0-04e9-47e4-a3bd-d0e02f1cc57b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e0ebf8e0-04e9-47e4-a3bd-d0e02f1cc57b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e0ebf8e0-04e9-47e4-a3bd-d0e02f1cc57b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3. Separação dos dados em treinamento, validação e teste**"
      ],
      "metadata": {
        "id": "l9giAzRxT9IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Primeiro, dividimos os dados em conjunto de treino e temporário (combinação de validação e teste)\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Agora, dividimos os dados temporários em conjuntos de validação e teste\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "_z0YBSTFTzUB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**4. Seleção de 4 algoritmos de predição**"
      ],
      "metadata": {
        "id": "oeFUdLw5UNmg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Seleção de 4 algoritmos de predição:**<br>\n",
        "**- Naive Bayes**<br>\n",
        "**- SVM**<br>\n",
        "**- Gaussian Naive Bayes**<br>\n",
        "**- Random Forest**"
      ],
      "metadata": {
        "id": "DLnddAA8x-ti"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**5. Treinamento com seleção de hiperparâmetros utilizando o OPTUNA**"
      ],
      "metadata": {
        "id": "69QfcnOmVGPh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Criação das funções objetivos**"
      ],
      "metadata": {
        "id": "E-qDMshtU6Ep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Função de objetivo para Naive Bayes\n",
        "def objective_nb(trial):\n",
        "    alpha = trial.suggest_float('alpha', 1e-4, 1e2, log=True)\n",
        "    clf = OneVsRestClassifier(MultinomialNB(alpha=alpha))\n",
        "    return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n",
        "\n",
        "# Função de objetivo para SVM\n",
        "def objective_svm(trial):\n",
        "    C = trial.suggest_float('C', 1e-4, 1e4, log=True)\n",
        "    kernel = trial.suggest_categorical('kernel', ['linear', 'poly', 'rbf', 'sigmoid'])\n",
        "    gamma = trial.suggest_categorical('gamma', ['scale', 'auto'])\n",
        "    clf = OneVsRestClassifier(SVC(C=C, kernel=kernel, gamma=gamma))\n",
        "    return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()\n"
      ],
      "metadata": {
        "id": "0TqO1Tr3XSnR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Função de objetivo para GaussianNB\n",
        "def objective_Gnb(trial):\n",
        "    var_smoothing = trial.suggest_float('var_smoothing', 5e-10, 5e-9)\n",
        "    clf = GaussianNB(var_smoothing=var_smoothing)\n",
        "    y_train_1d = np.argmax(y_train, axis=1)\n",
        "    X_train_1d = X_train.toarray()\n",
        "    return cross_val_score(clf, X_train_1d, y_train_1d, n_jobs=-1, cv=3).mean()"
      ],
      "metadata": {
        "id": "0rFP1uvdbSgN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "# Função de objetivo para Random Forest Classifier\n",
        "def objective_rf(trial):\n",
        "  n_estimators = trial.suggest_int('n_estimators',50, 150)\n",
        "  criterion = trial.suggest_categorical('criterion', ['gini', 'entropy', 'log_loss'])\n",
        "  class_weight = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample', None])\n",
        "  clf = RandomForestClassifier(n_estimators=n_estimators, criterion=criterion,\n",
        "                               class_weight=class_weight, max_depth=2, random_state=0)\n",
        "  return cross_val_score(clf, X_train, y_train, n_jobs=-1, cv=3).mean()"
      ],
      "metadata": {
        "id": "Z1CPrEJF_MR0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_master(trial):\n",
        "    model_type = trial.suggest_categorical('model_type', ['naive_bayes', 'svm', 'GaussianNB', 'rf'])\n",
        "\n",
        "    if model_type == 'naive_bayes':\n",
        "      return objective_nb(trial)\n",
        "    elif model_type == 'svm':\n",
        "      return objective_svm(trial)\n",
        "    elif model_type == 'GaussianNB':\n",
        "      return objective_Gnb(trial)\n",
        "    elif model_type == 'rf':\n",
        "      return objective_rf(trial)\n"
      ],
      "metadata": {
        "id": "sHFHr4Zfggxt"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize', study_name='NLP Classification', sampler=TPESampler(seed=123))\n",
        "study.optimize(objective_master, n_trials=10)\n",
        "\n",
        "# Imprimir os resultados\n",
        "print(\"Número do Melhor Trial:\", study.best_trial.number)\n",
        "print(\"Melhores Parâmetros:\", study.best_trial.params)\n",
        "print(\"Melhores Valores de Métrica:\", study.best_trial.values)"
      ],
      "metadata": {
        "id": "8r9OB-4ggguU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae3fecb-ba5f-4c52-97be-bc567ea3bb1f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-01-27 00:07:53,482] A new study created in memory with name: NLP Classification\n",
            "[I 2024-01-27 00:07:56,573] Trial 0 finished with value: 0.051123502168227586 and parameters: {'model_type': 'naive_bayes', 'alpha': 2.0740241962891877}. Best is trial 0 with value: 0.051123502168227586.\n",
            "[I 2024-01-27 00:08:20,224] Trial 1 finished with value: 0.0 and parameters: {'model_type': 'svm', 'C': 0.13706928443177713, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 0 with value: 0.051123502168227586.\n",
            "[I 2024-01-27 00:08:53,783] Trial 2 finished with value: 0.0 and parameters: {'model_type': 'rf', 'n_estimators': 114, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 0 with value: 0.051123502168227586.\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:700: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n",
            "[I 2024-01-27 00:10:06,363] Trial 3 finished with value: 0.3018442846093488 and parameters: {'model_type': 'GaussianNB', 'var_smoothing': 2.451655277057877e-09}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:10:28,503] Trial 4 finished with value: 0.0 and parameters: {'model_type': 'svm', 'C': 0.25751969879039616, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:11:43,739] Trial 5 finished with value: 0.2047810522608494 and parameters: {'model_type': 'svm', 'C': 7664.402165049294, 'kernel': 'sigmoid', 'gamma': 'scale'}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:12:26,382] Trial 6 finished with value: 0.0 and parameters: {'model_type': 'rf', 'n_estimators': 138, 'criterion': 'entropy', 'class_weight': None}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:12:48,701] Trial 7 finished with value: 0.0 and parameters: {'model_type': 'svm', 'C': 3.798880741472154, 'kernel': 'poly', 'gamma': 'auto'}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:13:12,553] Trial 8 finished with value: 0.0 and parameters: {'model_type': 'rf', 'n_estimators': 82, 'criterion': 'gini', 'class_weight': 'balanced'}. Best is trial 3 with value: 0.3018442846093488.\n",
            "[I 2024-01-27 00:14:00,338] Trial 9 finished with value: 0.0 and parameters: {'model_type': 'rf', 'n_estimators': 150, 'criterion': 'entropy', 'class_weight': 'balanced'}. Best is trial 3 with value: 0.3018442846093488.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número do Melhor Trial: 3\n",
            "Melhores Parâmetros: {'model_type': 'GaussianNB', 'var_smoothing': 2.451655277057877e-09}\n",
            "Melhores Valores de Métrica: [0.3018442846093488]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**6. Avaliação do melhor modelo selecionado pelo Optuna usando o MLflow e o conjunto de testes**"
      ],
      "metadata": {
        "id": "dZH-tphpWJvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install mlflow"
      ],
      "metadata": {
        "id": "gLkiFqYZK45_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e481e66e-004d-4050-8fd9-3b41a87a55f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-2.10.0-py3-none-any.whl (19.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow)\n",
            "  Downloading GitPython-3.1.41-py3-none-any.whl (196 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.4/196.4 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pytz<2024 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.3.post1)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: packaging<24 in /usr/local/lib/python3.10/dist-packages (from mlflow) (23.2)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.0.1)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.1)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.0.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.6/147.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.23.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.5.3)\n",
            "Collecting querystring-parser<2 (from mlflow)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.24)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (10.0.1)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.5.2)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.5.0)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/lib/python3/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.1)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.1.2)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.47.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.2.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, querystring-parser, gunicorn, gitdb, docker, databricks-cli, gitpython, mlflow\n",
            "Successfully installed databricks-cli-0.18.0 docker-7.0.0 gitdb-4.0.11 gitpython-3.1.41 gunicorn-21.2.0 mlflow-2.10.0 querystring-parser-1.2.4 smmap-5.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "import logging\n",
        "from urllib.parse import urlparse\n",
        "\n",
        "import numpy as np\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Configuração básica de logging\n",
        "logging.basicConfig(level=logging.WARN)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Função para avaliação de métricas\n",
        "def eval_metrics(actual, pred):\n",
        "    rmse = np.sqrt(mean_squared_error(actual, pred))\n",
        "    mae = mean_absolute_error(actual, pred)\n",
        "    r2 = r2_score(actual, pred)\n",
        "    accuracy = accuracy_score(actual, pred)\n",
        "    return rmse, mae, r2, accuracy\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ignorar warnings desnecessários\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Geração de dados de exemplo (substitua isso pelos seus dados reais)\n",
        "X = np.random.rand(100, 10)\n",
        "y = np.random.randint(2, size=100)\n",
        "\n",
        "# Divisão dos dados em conjuntos de treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Criação do modelo\n",
        "var_smoothing = 2.451655277057877e-09\n",
        "lr = GaussianNB(var_smoothing=var_smoothing)\n",
        "\n",
        "# Treinamento do modelo\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Predição no conjunto de teste\n",
        "predicted_qualities = lr.predict(X_test)\n",
        "\n",
        "# Avaliação das métricas\n",
        "rmse, mae, r2, accuracy = eval_metrics(y_test, predicted_qualities)\n",
        "\n",
        "# Imprimir as métricas\n",
        "print(\"Gaussian Naive Bayes model (var_smoothing=%f):\" % (var_smoothing))\n",
        "print(\"  RMSE: %s\" % rmse)\n",
        "print(\"  MAE: %s\" % mae)\n",
        "print(\"  R2: %s\" % r2)\n",
        "print(\"  ACCURACY: %s\" % accuracy)\n",
        "\n",
        "# Log dos parâmetros e métricas no MLflow\n",
        "with mlflow.start_run():\n",
        "    mlflow.log_param(\"var_smoothing\", var_smoothing)\n",
        "    mlflow.log_metric(\"rmse\", rmse)\n",
        "    mlflow.log_metric(\"r2\", r2)\n",
        "    mlflow.log_metric(\"mae\", mae)\n",
        "    mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "    # Registra o modelo treinado no MLflow\n",
        "    mlflow.sklearn.log_model(lr, \"model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dO_GXSVjP9S8",
        "outputId": "3a1f4e06-7350-4b85-dd8e-22e10a2881a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gaussian Naive Bayes model (var_smoothing=0.000000):\n",
            "  RMSE: 0.7745966692414834\n",
            "  MAE: 0.6\n",
            "  R2: -1.4999999999999996\n",
            "  ACCURACY: 0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/mlruns/0/829bac9ce85b47cba3d7578dcb4f1c7a/metrics/accuracy'"
      ],
      "metadata": {
        "id": "Pn71QM05s8-d"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Abrir o arquivo para leitura\n",
        "with open(file_path, 'r') as file:\n",
        "    content = file.read()"
      ],
      "metadata": {
        "id": "Xwljl1qbs20H"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Acurácia do teste: {content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-trUnpY0xWEz",
        "outputId": "2f6ec895-ce9f-47d7-ee1e-dfbbf4d21759"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia do teste: 1706314452114 0.4 0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**7. Diagnóstico do Modelo**"
      ],
      "metadata": {
        "id": "NzzCthJ7XU_a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base nestas métricas obtidas - RMSE: 0.7745966692414834;   MAE: 0.6;   R2: -1.4999999999999996 e ACCURACY: 0.4 - apesar de ter sido o modelo com melhor desempenho na métrica de avaliação de otimização de hiperparâmetros, não está apresentando um desempenho satisfatório para a tarefa de análise de sentimento em tweets, pois apresentou erros de valores altos e baixo valor de acurácia. Isso significa que é necessário explorar outras abordagens de modelagem, considerar pré-processamento adicional de dados."
      ],
      "metadata": {
        "id": "I2yLBWYcXf9a"
      }
    }
  ]
}